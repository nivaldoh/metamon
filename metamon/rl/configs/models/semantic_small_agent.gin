import amago.nets.actor_critic
import amago.nets.traj_encoders
import amago.agent
import amago.experiment

# Base experiment configuration
MetamonAMAGOExperiment.agent_type = @agent.Agent
MetamonAMAGOExperiment.tstep_encoder_type = @MetamonTstepEncoder
MetamonAMAGOExperiment.traj_encoder_type = @traj_encoders.TformerTrajEncoder
MetamonAMAGOExperiment.max_seq_len = 50  # Very short sequences for testing

# Small Semantic Actor Configuration
Agent.actor_type = @MetamonSemanticActor
Agent.pass_obs_keys_to_actor = ["illegal_actions"]

# Small model hyperparameters (MINIMAL for testing)
MetamonSemanticActor.mask_illegal_actions = True
MetamonSemanticActor.descriptor_hidden_dim = 32  # Very small
MetamonSemanticActor.action_emb_dim = 16  # Very small
MetamonSemanticActor.num_attention_heads = 1  # Single head
MetamonSemanticActor.use_gate = True
MetamonSemanticActor.use_bilinear_scoring = False
MetamonSemanticActor.dropout = 0.05
MetamonSemanticActor.normalize_descriptors = True
MetamonSemanticActor.cache_embeddings = True
MetamonSemanticActor.fallback_mlp = False

# Critic configuration
Agent.critic_type = @actor_critic.NCritics
actor_critic.NCritics.activation = "leaky_relu"
actor_critic.NCritics.n_layers = 2
actor_critic.NCritics.d_hidden = 256  # Smaller
Agent.popart = True
Agent.num_critics = 2  # Fewer critics

# Turn embedding architecture (smaller)
MetamonTstepEncoder.extra_emb_dim = 16
MetamonTstepEncoder.d_model = 64  # Smaller
MetamonTstepEncoder.n_layers = 2
MetamonTstepEncoder.n_heads = 4
MetamonTstepEncoder.scratch_tokens = 2
MetamonTstepEncoder.numerical_tokens = 4
MetamonTstepEncoder.token_mask_aug = False
MetamonTstepEncoder.dropout = 0.05

# Trajectory encoder (smaller transformer)
traj_encoders.TformerTrajEncoder.n_layers = 2
traj_encoders.TformerTrajEncoder.n_heads = 4
traj_encoders.TformerTrajEncoder.d_ff = 1024
traj_encoders.TformerTrajEncoder.d_model = 256
traj_encoders.TformerTrajEncoder.normformer_norms = True
traj_encoders.TformerTrajEncoder.sigma_reparam = True
traj_encoders.TformerTrajEncoder.norm = "layer"
traj_encoders.TformerTrajEncoder.head_scaling = True
traj_encoders.TformerTrajEncoder.activation = "leaky_relu"